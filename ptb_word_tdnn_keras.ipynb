{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "I have yet to conclude training the model, but I was to excited to share it finally working after a long time.\n",
    "On a side note, however, it does seem to overfit before the end of even the first epoch, but we need to conclude a whole training session before jumping to any conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Prediction using TDNN implemented in tf.keras\n",
    "This notebook is an attempt at implementing a Time Delay Neural Network for word prediction in the ptb dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from __future__ import print_function\n",
    "import tensorboard as tf\n",
    "from tensorflow import keras\n",
    "import reader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "window_size = 20 # defines the past lookup for determining the following word\n",
    "path = \"data/simple-examples/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell obtain the data using the reader.py file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data, vocab_size, word_to_id = reader.ptb_raw_data(path)\n",
    "x_train = train_data[:-1]\n",
    "x_train = [np.asarray(x_train[i:i+window_size]) for i in range(len(x_train)-window_size)]\n",
    "x_train = np.asarray(x_train)\n",
    "y_train = np.asarray(train_data[1:-window_size])\n",
    "#y_train = keras.preprocessing.text.one_hot(y_train, vocab_size)\n",
    "x_valid = valid_data[:-1]\n",
    "x_valid = [np.asarray(x_valid[i:i+window_size]) for i in range(len(x_valid)-window_size)]\n",
    "x_valid = np.asarray(x_valid)\n",
    "y_valid = valid_data[1:-window_size]\n",
    "y_valid = np.asarray(y_valid)\n",
    "x_test = test_data[:-1]\n",
    "x_test = [np.asarray(x_test[i:i+window_size]) for i in range(len(x_test)-window_size)]\n",
    "x_test = np.asarray(x_test)\n",
    "y_test = test_data[1:-window_size]\n",
    "y_test = np.asarray(y_test)\n",
    "id_to_word = {value: key for (key, value) in word_to_id.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following next, we have an auxiliary function which decodes the ids and give us the original sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_text(text):\n",
    "    return ' '.join([id_to_word.get(i, '?') for i in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<eos> mr. <unk> is chairman of <unk> n.v. the dutch publishing group <eos> rudolph <unk> N years old and former'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_text (x_train[40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(929568, 20)\n",
      "(929568,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, each index of the input has a length of 20 words, as defined in _window-length_\n",
    "<br>\n",
    "With our data already processed, we can finally create our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 20, 16)\n",
      "(None, 20, 1)\n",
      "(None, 20, 1)\n",
      "(None, 20)\n",
      "(None, 10000)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(vocab_size, 16, input_length = window_size))\n",
    "#model.add(keras.layers.Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(keras.layers.Conv1D(filters = 1, kernel_size = 3, padding = \"same\", activation = keras.activations.tanh))\n",
    "print(model.output_shape)\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Conv1D(filters = 1, kernel_size = 3, padding = \"same\", activation = keras.activations.tanh))\n",
    "print(model.output_shape)\n",
    "model.add(keras.layers.Dropout(0.25))\n",
    "model.add(keras.layers.Flatten())\n",
    "print(model.output_shape)\n",
    "model.add(keras.layers.Dense(vocab_size, activation = keras.activations.softmax))\n",
    "print(model.output_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_8 (Embedding)      (None, 20, 16)            160000    \n",
      "_________________________________________________________________\n",
      "conv1d_15 (Conv1D)           (None, 20, 1)             49        \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 20, 1)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 20, 1)             4         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 20, 1)             0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10000)             210000    \n",
      "=================================================================\n",
      "Total params: 370,053\n",
      "Trainable params: 370,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print (model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss = keras.losses.sparse_categorical_crossentropy,\n",
    "    optimizer = keras.optimizers.Adadelta(),\n",
    "    metrics = [keras.metrics.categorical_accuracy] # remember to later change to sparse_categorical_accuracy (this is the cause for strange eval)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 929568 samples, validate on 73739 samples\n",
      "Epoch 1/12\n",
      "929568/929568 [==============================] - 900s 968us/step - loss: 6.8354 - categorical_accuracy: 0.5550 - val_loss: 6.7577 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 2/12\n",
      "929568/929568 [==============================] - 814s 876us/step - loss: 6.7952 - categorical_accuracy: 0.5676 - val_loss: 6.7580 - val_categorical_accuracy: 1.0000\n",
      "Epoch 3/12\n",
      "929568/929568 [==============================] - 759s 817us/step - loss: 6.7873 - categorical_accuracy: 0.5706 - val_loss: 6.7579 - val_categorical_accuracy: 1.0000\n",
      "Epoch 4/12\n",
      "929568/929568 [==============================] - 749s 805us/step - loss: 6.7811 - categorical_accuracy: 0.5747 - val_loss: 6.7594 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 5/12\n",
      "929568/929568 [==============================] - 939s 1ms/step - loss: 6.7768 - categorical_accuracy: 0.5700 - val_loss: 6.7599 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 6/12\n",
      "929568/929568 [==============================] - 862s 928us/step - loss: 6.7744 - categorical_accuracy: 0.5712 - val_loss: 6.7593 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 7/12\n",
      "929568/929568 [==============================] - 745s 802us/step - loss: 6.7722 - categorical_accuracy: 0.5680 - val_loss: 6.7597 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 8/12\n",
      "929568/929568 [==============================] - 782s 841us/step - loss: 6.7707 - categorical_accuracy: 0.5667 - val_loss: 6.7587 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 9/12\n",
      "929568/929568 [==============================] - 803s 864us/step - loss: 6.7695 - categorical_accuracy: 0.5647 - val_loss: 6.7590 - val_categorical_accuracy: 0.0000e+00\n",
      "Epoch 10/12\n",
      "929568/929568 [==============================] - 756s 813us/step - loss: 6.4118 - categorical_accuracy: 0.4233 - val_loss: 5.7271 - val_categorical_accuracy: 0.1840\n",
      "Epoch 11/12\n",
      "929568/929568 [==============================] - 750s 807us/step - loss: 6.0182 - categorical_accuracy: 0.2451 - val_loss: 5.6212 - val_categorical_accuracy: 0.1828\n",
      "Epoch 12/12\n",
      "929568/929568 [==============================] - 875s 941us/step - loss: 5.9941 - categorical_accuracy: 0.2719 - val_loss: 5.5836 - val_categorical_accuracy: 0.1858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x7f7b656c00b8>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          epochs = 12,\n",
    "          verbose = 1,\n",
    "          validation_data = (x_valid, y_valid),\n",
    "          shuffle = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.541705676066773\n",
      "Test accuracy: 0.18199468504653618\n"
     ]
    }
   ],
   "source": [
    "# I expect to be able to run this someday\n",
    "score = model.evaluate(x_test, y_test, verbose = 0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
